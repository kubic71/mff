# Should we allow AI to predict human behaviour
- AI observing human behavior, predicts following sequence of agent actions

## is it useful?
- artificial nurse for surgeons
    - should understand the intents of a surgeon, prepare tools
- self-driving
    - understand the intents of other drivers
- security
    - predict crime
- in general
    - AI needs to model the environment, of which humans are part of

## Can it backfire?
- guilty until proven innocent
- transparency
- bias
- general unintended consequences
    - 2nd, 3rd order effects


## Yes team
- predicting is natural

### Use-cases
- emergency prediction
    - ex: fire in the room
    - AI can design better emergency systems
    - anomaly prediction
    - interrogation AI systems
        - predicts innocence - Q: runaway feedback loop?
    - market prediction
- design better social policies
- personalized education
    - Q: should the AI decide without the person knowing and understanding its decision?
- help businesses

### Problem of control
- can we trust predictive AI?
- AI should learn our preferences from our behavior
    - cannot be done without behavior modelling

### Problems
- counter terrorism
    - more an assist system, not sending to jail immediately
- crime
    - trust authorities
- bias
    - humans are biased, AI is less biased
    - Q: where do you get you training data? Wouldn't the AI predictions bias the future training data?
        - two groups, A and B
        - A commits more crime, B less
        - AI focuses on A, so higher percantage of crimes commited by of A will be revealed
        - analogously smaller precentage of crimes commited by B will be revealed
        - the future training dataset gets more biased
        - 2nd order effect - A gets depressed, B thinks they are untouchable
        - 3rd order effects - depressed A don't make most of their lives, earn less, and as an effect 

### Security
- short term, immediate predictions
- assistant
- AI has more computation power than humans

## No team

### Why not?
- manipulation
    - business insight
    - election prediction
    - can just knowing the predictions affect humuns in negative way?
- good AI needs good data
    - privacy issues
- low accuracy, false interpretation
    - hard to distinguish false positives for true positives
- bias
    - almost impossible to design unbiased AI
        - low explainability, we don't even biased predictions happen
    - high-accuracy AI will neccesarily be racist and biased
- can spiral out of control
    - selecting people for checks often makes them thing they are criminals, wierd
- hard to regulate
    - programmer
- interpretable models
    - hard to interpret, only by a few chosen people


### Inter-team questions
- what should be the response of humans in the case of uncertain predictions? Probability prediction threshold?
